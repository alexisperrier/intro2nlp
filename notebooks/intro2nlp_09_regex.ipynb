{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Information With Regular Expression\n",
    "\n",
    "\n",
    "[![Open In Colab](colab-badge.svg)](https://colab.research.google.com/github/alexisperrier/intro2nlp/blob/master/notebooks/intro2nlp_09_regex.ipynb)\n",
    "\n",
    "Wikipedia: A [regular expression](https://en.wikipedia.org/wiki/Regular_expression) is a sequence of characters that define a search pattern. Usually such patterns are used by string-searching algorithms for \"find\" or \"find and replace\" operations on strings, or for input validation.\n",
    "\n",
    "In this notebook we will go over a series of handy regex patterns and see how to use them. The goal is to use the regex not to learn how to build whole regex patterns from scratch.\n",
    "\n",
    "Regex is a super useful tool when working with text. It allows you to quickly extract or replace patterns in a long text. It's reliable, lightning fast and flexible.\n",
    "\n",
    "But it does take getting used to using cryptic pattern definitions.\n",
    "\n",
    "We'll start simple with :\n",
    "- finding #hashtags in tweets\n",
    "- extracting and replacing @usernames "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hashtags\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is a small corpus of tweets that contain hashtags\n",
    "tweets = [\n",
    "    'An #autumn scene showing a beautiful #horse coming to visit me.', \n",
    "    'My new favourite eatery in #liverpool and I mean superb! #TheBrunchClub #breakfast #food', \n",
    "    '#nowplaying Pointer Sisters - Dare Me | #80s #disco #funk #radio']\n",
    "    \n",
    "# import the regex module\n",
    "import re\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the pattern\n",
    "\n",
    "This pattern find all the sequences of characters \n",
    "with the exclusion of spaces, tabs, line returns ...\n",
    "that start with a # sign:\n",
    "\n",
    "\n",
    "```# followed by a non empty sequence of letters and punctuation signs: S+```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'#\\S+'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use ```re.findall``` to extract all the elements from the text that match the pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in tweets:\n",
    "    print(re.findall(pattern, text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# @usernames\n",
    "\n",
    "Slightly modify the pattern to find all the @usernames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "text = 'Check out this new NLP course on @openclassrooms by @alexip'\n",
    "    \n",
    "# change the pattern # -> @\n",
    "pattern = r'@\\S+' \n",
    "\n",
    "print(re.findall(pattern, text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use ```re.sub``` to replace all the usernames by a special token.\n",
    "\n",
    "For instance replace the usernames with the token USR. The pattern stay the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\t\",text)\n",
    "print(\"becomes:\")\n",
    "print(\"\\t\",re.sub(pattern, 'USR', text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# remove html tags\n",
    "\n",
    "A slightly more complex example. We have a web page and we want to remove all the html tags. Html tags are represented by ```< some text >```. \n",
    "\n",
    "So we want to remove all the elements that are comprised between ```<``` and ```>``` including the brackets.\n",
    "\n",
    "\n",
    "We define the pattern\n",
    "\n",
    "```\n",
    "pattern = r\"<[^>]*>\"\n",
    "```\n",
    "\n",
    "Let's apply that to a web page that we download raw from wikipedia. \n",
    "For a change consider the page about [House Music](https://en.wikipedia.org/wiki/House_music). The ```html``` element contains the raw html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "\n",
    "# Music is in the House!\n",
    "url = 'https://en.wikipedia.org/wiki/House_music'\n",
    "\n",
    "# GET the content \n",
    "# Note: requests.get().content returns a byte object \n",
    "# that we can cast as string with .decode('UTF-8')\n",
    "html = requests.get(url).content.decode('UTF-8')\n",
    "\n",
    "# remove the header part of the html \n",
    "html = html.split('</head>')[1]\n",
    "\n",
    "print(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now remove all the html tags with ```re.sub```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r\"<[^>]*>\"\n",
    "text = re.sub(pattern,' ', html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "no more html tags, just raw text!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting urls\n",
    "\n",
    "If we just remove all the html tags we also remove all the links which are in the form ``` <a href=\"some url> ... </a>\"```. \n",
    "\n",
    "So we may also want to extract the urls from a web page. \n",
    "For instance if you want to list the sources cited on social networks or build a bot that follows the links from a web page.\n",
    "\n",
    "To extract the urls we will use the following pattern\n",
    "\n",
    "```\n",
    "r'http.+?(?=\"|<)'\n",
    "```\n",
    "\n",
    "This pattern finds all strings that start with http and end with either \" or <\n",
    "\n",
    "Let's extract the urls from the wikipedia [House Music](https://en.wikipedia.org/wiki/House_music) page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/House_music'\n",
    "html = requests.get(url).content.decode('UTF-8').split('</head>')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'http.+?(?=\\?|\"|<)'\n",
    "urls = re.findall(pattern, html)\n",
    "print(f\"We find {len(urls)} urls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(f\"- {urls[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Punctuation signs\n",
    "\n",
    "We can also use a regex to remove all the punctuation signs from a text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Hello, is your name bob? \"\n",
    "\n",
    "print(text)\n",
    "\n",
    "print(re.sub(r'[^\\w\\s]', '', text) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "\n",
    "The following pattern makes a decent tokenizer when used with the split function\n",
    "\n",
    "```r\"\\b\\w+\\b\"```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Hello, is your name bob? \"\n",
    "re.findall(r\"\\b\\w+\\b\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
